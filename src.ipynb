{
 "cells": [
  {
   "cell_type": "code",
   "id": "d0fee7d45c8184a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T07:23:54.970587Z",
     "start_time": "2025-12-20T07:23:54.949993Z"
    }
   },
   "source": [
    "# # 1Ô∏è‚É£ Create a new virtual environment (name it 'venv_tf' or anything)\n",
    "# !python -m venv venv_face_identify\n",
    "#\n",
    "# # 2Ô∏è‚É£ Activate it (Windows-specific)\n",
    "# !venv_face_identify\\Scripts\\activate\n",
    "#\n",
    "# # 3Ô∏è‚É£ Upgrade pip and install Jupyter into this venv\n",
    "# !venv_face_identify\\Scripts\\python -m pip install --upgrade pip\n",
    "# !venv_face_identify\\Scripts\\python -m pip install jupyter ipykernel\n",
    "#\n",
    "# # 4Ô∏è‚É£ Add this environment as a Jupyter kernel\n",
    "# !venv_face_identify\\Scripts\\python -m ipykernel install --user --name=venv_face_identify --display-name \"Python (venv_face_identify)\"\n"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "id": "976cf377ddb09bd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T07:23:55.029989Z",
     "start_time": "2025-12-20T07:23:55.019015Z"
    }
   },
   "source": [
    "#%pip install numpy pandas matplotlib tensorflow torch facenet-pytorch scikit-learn opencv-python tqdm pillow\n"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "id": "9804867f58b98631",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-12-20T07:23:55.136851Z",
     "start_time": "2025-12-20T07:23:55.118250Z"
    }
   },
   "source": [
    "# BLOCK 1 ‚Äî Configuration Block (edit only DATA_ROOT)\n",
    "# Directory/Path Define\n",
    "\n",
    "DATA_ROOT = \"human_face_dataset/pins_face_recognition\"  # << set this to your dataset folder (one subfolder per person)\n",
    "# Block 1 ‚Äî Imports & configuration\n",
    "from pathlib import Path\n",
    "import os, time, pickle, hashlib\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# ---------- EDIT IF NEEDED ----------\n",
    "# Set DATA_ROOT to the folder that contains one folder per person (images inside)\n",
    "DATA_ROOT = \"human_face_dataset/pins_face_recognition\"\n",
    "# ------------------------------------\n",
    "\n",
    "# Cache & artifact locations\n",
    "CACHE_DIR = Path('./embeddings_cache'); CACHE_DIR.mkdir(exist_ok=True)\n",
    "EMB_FILE = CACHE_DIR / 'X_emb.npy'\n",
    "LBL_FILE = CACHE_DIR / 'y_lbl.npy'\n",
    "PATHS_FILE = CACHE_DIR / 'paths.npy'\n",
    "CLF_FILE = CACHE_DIR / 'svc_model_retrained.pkl'\n",
    "CENTROIDS_FILE = CACHE_DIR / 'centroids.npy'\n",
    "CLASSES_FILE = CACHE_DIR / 'classes.npy'\n",
    "\n",
    "# Image extensions considered\n",
    "EXTS = {'.jpg', '.jpeg', '.png'}\n",
    "print(\"DATA_ROOT:\", DATA_ROOT)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_ROOT: human_face_dataset/pins_face_recognition\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "id": "79caa6dce9652eb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T07:24:01.263928Z",
     "start_time": "2025-12-20T07:23:55.275297Z"
    }
   },
   "source": [
    "# Block 2 ‚Äî Imports and Model initialization (facenet-pytorch)\n",
    "try:\n",
    "    from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "    import torch\n",
    "    import cv2\n",
    "    from PIL import Image\n",
    "except Exception as e:\n",
    "    raise ImportError(\"Missing packages. Run pip install facenet-pytorch torch torchvision opencv-python scikit-learn tqdm matplotlib pillow\") from e\n",
    "\n",
    "device = 'cpu'\n",
    "mtcnn = MTCNN(keep_all=False, device=device)          # detector + alignment\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval()  # embedding model (512-d)\n",
    "print(\"Models ready. Device:\", device)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models ready. Device: cpu\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "id": "d9ee095eaffe8042",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T07:24:05.524967Z",
     "start_time": "2025-12-20T07:24:05.491965Z"
    }
   },
   "source": [
    "# BLOCK 3: Move duplicate files into ./duplicates/ (safe)\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# `dupes` is the dict you produced mapping md5 -> [paths], or re-find below\n",
    "def find_duplicates(paths):\n",
    "    import hashlib\n",
    "    from collections import defaultdict\n",
    "    def h(p):\n",
    "        m = hashlib.md5()\n",
    "        with open(p,'rb') as f:\n",
    "            for chunk in iter(lambda: f.read(8192), b''):\n",
    "                m.update(chunk)\n",
    "        return m.hexdigest()\n",
    "    D = defaultdict(list)\n",
    "    for p in paths:\n",
    "        D[h(p)].append(p)\n",
    "    return {k:v for k,v in D.items() if len(v)>1}\n",
    "\n",
    "# Build paths list (adjust root)\n",
    "root = Path(r'D:\\DATA_SCIENCE\\My_Projects\\testing\\human_face_identify\\pins_face_recognition')\n",
    "paths = [str(p) for p in root.rglob('*') if p.suffix.lower() in ('.jpg','.jpeg','.png')]\n",
    "dupes = find_duplicates(paths)\n",
    "\n",
    "outdir = Path('./duplicates'); outdir.mkdir(exist_ok=True)\n",
    "moved = 0\n",
    "for h, lst in dupes.items():\n",
    "    keep = lst[0]            # keep first occurrence\n",
    "    for p in lst[1:]:\n",
    "        target = outdir / Path(p).name\n",
    "        # avoid name collisions\n",
    "        i = 1\n",
    "        while target.exists():\n",
    "            target = outdir / f\"{Path(p).stem}_{i}{Path(p).suffix}\"\n",
    "            i += 1\n",
    "        shutil.move(p, str(target))\n",
    "        moved += 1\n",
    "print(f\"Moved {moved} duplicate files to {outdir}. Kept first occurrence of each duplicated image.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved 0 duplicate files to duplicates. Kept first occurrence of each duplicated image.\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T07:24:05.805758Z",
     "start_time": "2025-12-20T07:24:05.678465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Explicitly point to the 'data' folder\n",
    "image_path = Path(\"data\")\n",
    "\n",
    "# Use rglob to find images even if they are in subfolders within 'data'\n",
    "# The '*' catches any filename, and suffix check handles extension cases\n",
    "images = [f for f in image_path.rglob(\"*\") if f.suffix.lower() in [\".png\", \".jpg\", \".jpeg\"]]\n",
    "\n",
    "print(f\"Found {len(images)} images in {image_path.absolute()}\")"
   ],
   "id": "7ffdd0b95d5b0ea5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3365 images in D:\\DATA_SCIENCE\\My_Projects\\completed\\Git_Repositories\\face_recognition_streamlit _App\\data\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T07:24:06.179381Z",
     "start_time": "2025-12-20T07:24:05.969020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Block 4 ‚Äî Data Count & Define Image Path for the operation\n",
    "# Build image_paths and labels and save to cache (paths.npy)\n",
    "\n",
    "from pathlib import Path\n",
    "ROOT = Path(\"data\")\n",
    "image_paths = [str(p) for p in sorted(ROOT.rglob('*')) if p.suffix.lower() in EXTS]\n",
    "labels = [Path(p).parent.name for p in image_paths]\n",
    "print(\"Classes found:\", len(set(labels)), \"Total images:\", len(image_paths))\n",
    "# Save list of paths to allow deduping later or resume\n",
    "np.save(PATHS_FILE, np.array(image_paths, dtype=object))\n",
    "print(\"Saved paths to\", PATHS_FILE)\n"
   ],
   "id": "2def8cd3d4a8d90c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes found: 21 Total images: 3365\n",
      "Saved paths to embeddings_cache\\paths.npy\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "id": "5fc6980927c76bde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T07:24:06.407411Z",
     "start_time": "2025-12-20T07:24:06.270672Z"
    }
   },
   "source": [
    "# Block 5: (Embedding Block)\n",
    "# Batched, resumable extraction to EMB_FILE / LBL_FILE (overwrite/resume)\n",
    "\n",
    "import numpy as np, torch\n",
    "from PIL import Image\n",
    "from math import ceil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# parameters: tune for your machine\n",
    "BATCH_SIZE = 48     # try 16/32/48/64 depending on RAM\n",
    "SAVE_EVERY = 1      # save after this many batches\n",
    "MAX_SIDE = 640      # resize max side for speed; lower to 480 if needed\n",
    "\n",
    "# load list of all paths\n",
    "image_paths = list(np.load(PATHS_FILE, allow_pickle=True))\n",
    "n_total = len(image_paths)\n",
    "\n",
    "# resume from cache if exists\n",
    "if EMB_FILE.exists() and LBL_FILE.exists():\n",
    "    X_cached = np.load(EMB_FILE)\n",
    "    y_cached = np.load(LBL_FILE, allow_pickle=True)\n",
    "    start_idx = len(y_cached)\n",
    "    X_list = [X_cached[i] for i in range(len(X_cached))]\n",
    "    y_list = [y_cached[i] for i in range(len(y_cached))]\n",
    "    print(f\"Resuming from cache: {start_idx} embeddings loaded.\")\n",
    "else:\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    start_idx = 0\n",
    "\n",
    "def safe_open_resize(path, max_side=MAX_SIDE):\n",
    "    try:\n",
    "        im = Image.open(path).convert('RGB')\n",
    "        w,h = im.size\n",
    "        s = max(w,h)\n",
    "        if s > max_side:\n",
    "            scale = max_side / s\n",
    "            im = im.resize((int(w*scale), int(h*scale)), Image.BILINEAR)\n",
    "        return im\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "pairs = image_paths[start_idx:]\n",
    "n = len(pairs)\n",
    "if n == 0:\n",
    "    print(\"No new images to process.\")\n",
    "else:\n",
    "    n_batches = ceil(n / BATCH_SIZE)\n",
    "    print(f\"Processing {n} images in {n_batches} batches (batch_size={BATCH_SIZE})\")\n",
    "    bad_files = []\n",
    "    batch_count = 0\n",
    "    t_total = time.time()\n",
    "    for b in tqdm(range(n_batches), desc='Batches'):\n",
    "        s = b * BATCH_SIZE\n",
    "        e = min(s + BATCH_SIZE, n)\n",
    "        batch_paths = pairs[s:e]\n",
    "        pil_imgs = []\n",
    "        pil_labels = []\n",
    "        real_paths = []\n",
    "        for path in batch_paths:\n",
    "            im = safe_open_resize(path)\n",
    "            if im is None:\n",
    "                bad_files.append(path)\n",
    "                continue\n",
    "            pil_imgs.append(im)\n",
    "            pil_labels.append(Path(path).parent.name)\n",
    "            real_paths.append(path)\n",
    "        if not pil_imgs:\n",
    "            batch_count += 1\n",
    "            continue\n",
    "\n",
    "        # try batch detection; fallback to per-image if needed\n",
    "        faces = None\n",
    "        try:\n",
    "            faces = mtcnn(pil_imgs)\n",
    "        except Exception as ex:\n",
    "            faces = None\n",
    "            # fallback will run below\n",
    "\n",
    "        face_tensors = []\n",
    "        valid_labels = []\n",
    "        if isinstance(faces, torch.Tensor):\n",
    "            # tensor -> all faces detected and aligned\n",
    "            for i in range(faces.shape[0]):\n",
    "                f = faces[i].unsqueeze(0)\n",
    "                face_tensors.append(f)\n",
    "                valid_labels.append(pil_labels[i])\n",
    "        else:\n",
    "            # fallback to per-image detection\n",
    "            for im, lab, path in zip(pil_imgs, pil_labels, real_paths):\n",
    "                try:\n",
    "                    f = mtcnn(im)\n",
    "                    if f is None:\n",
    "                        bad_files.append(path)\n",
    "                        continue\n",
    "                    if f.dim() == 3:\n",
    "                        f = f.unsqueeze(0)\n",
    "                    face_tensors.append(f)\n",
    "                    valid_labels.append(lab)\n",
    "                except Exception:\n",
    "                    bad_files.append(path)\n",
    "                    continue\n",
    "\n",
    "        if not face_tensors:\n",
    "            batch_count += 1\n",
    "            if batch_count % SAVE_EVERY == 0 and len(y_list) > 0:\n",
    "                np.save(EMB_FILE, np.vstack(X_list))\n",
    "                np.save(LBL_FILE, np.array(y_list, dtype=object))\n",
    "            continue\n",
    "\n",
    "        face_batch = torch.cat(face_tensors, dim=0)\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                emb_batch = resnet(face_batch).cpu().numpy()\n",
    "        except Exception:\n",
    "            # per-item embedding fallback\n",
    "            emb_batch = []\n",
    "            for ft in face_tensors:\n",
    "                try:\n",
    "                    with torch.no_grad():\n",
    "                        e = resnet(ft).cpu().numpy().reshape(-1)\n",
    "                    emb_batch.append(e)\n",
    "                except Exception:\n",
    "                    emb_batch.append(None)\n",
    "            filtered = [(e, lab) for e, lab in zip(emb_batch, valid_labels) if e is not None]\n",
    "            if not filtered:\n",
    "                batch_count += 1\n",
    "                continue\n",
    "            emb_batch = np.vstack([f[0] for f in filtered])\n",
    "            valid_labels = [f[1] for f in filtered]\n",
    "\n",
    "        for emb, lab in zip(emb_batch, valid_labels):\n",
    "            X_list.append(emb.astype('float32'))\n",
    "            y_list.append(lab)\n",
    "\n",
    "        batch_count += 1\n",
    "        if batch_count % SAVE_EVERY == 0:\n",
    "            np.save(EMB_FILE, np.vstack(X_list))\n",
    "            np.save(LBL_FILE, np.array(y_list, dtype=object))\n",
    "            t_elapsed = time.time() - t_total\n",
    "            processed = len(y_list)\n",
    "            rate = processed / t_elapsed if t_elapsed > 0 else 0\n",
    "            print(f\"Saved cache: {len(y_list)} embeddings; rate {rate:.2f} emb/s\")\n",
    "\n",
    "    # final save\n",
    "    if len(X_list) > 0:\n",
    "        X = np.vstack(X_list).astype('float32')\n",
    "        y = np.array(y_list, dtype=object)\n",
    "        np.save(EMB_FILE, X)\n",
    "        np.save(LBL_FILE, y)\n",
    "        np.save(PATHS_FILE, np.array(image_paths, dtype=object))  # ensure paths saved\n",
    "        print(\"Done. Extracted embeddings:\", X.shape)\n",
    "    else:\n",
    "        print(\"No embeddings extracted in this run.\")\n",
    "\n",
    "    if bad_files:\n",
    "        bad_txt = CACHE_DIR / 'bad_files.txt'\n",
    "        with open(bad_txt, 'w', encoding='utf-8') as f:\n",
    "            for p in sorted(set(bad_files)):\n",
    "                f.write(p + \"\\n\")\n",
    "        print(f\"{len(set(bad_files))} problematic files logged to {bad_txt}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from cache: 3365 embeddings loaded.\n",
      "No new images to process.\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "id": "109a7be90dac3b1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T07:24:12.728423Z",
     "start_time": "2025-12-20T07:24:06.485386Z"
    }
   },
   "source": [
    "# Block 6 ‚Äî deduplicate embeddings using file MD5 (optional)\n",
    "if not EMB_FILE.exists() or not PATHS_FILE.exists():\n",
    "    print(\"Embeddings or paths missing. Run Block 5 first.\")\n",
    "else:\n",
    "    X = np.load(EMB_FILE)\n",
    "    y = np.load(LBL_FILE, allow_pickle=True)\n",
    "    paths = list(np.load(PATHS_FILE, allow_pickle=True))\n",
    "    print(\"Loaded:\", X.shape, len(paths))\n",
    "    seen = {}\n",
    "    keep_idx = []\n",
    "    for i, p in enumerate(paths):\n",
    "        try:\n",
    "            h = hashlib.md5(open(p, 'rb').read()).hexdigest()\n",
    "        except Exception:\n",
    "            continue\n",
    "        if h in seen:\n",
    "            continue\n",
    "        seen[h] = i\n",
    "        keep_idx.append(i)\n",
    "    print(\"Unique images:\", len(keep_idx), \"of\", len(paths))\n",
    "    X_new = X[keep_idx]\n",
    "    y_new = y[keep_idx]\n",
    "    paths_new = [paths[i] for i in keep_idx]\n",
    "    np.save(CACHE_DIR / 'X_emb_dedup.npy', X_new)\n",
    "    np.save(CACHE_DIR / 'y_lbl_dedup.npy', y_new)\n",
    "    np.save(CACHE_DIR / 'paths_dedup.npy', np.array(paths_new, dtype=object))\n",
    "    print(\"Saved deduplicated embeddings to embeddings_cache/*.\")\n",
    "    # If you want to use deduped files as main, replace originals (manual step)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: (3365, 512) 3365\n",
      "Unique images: 3364 of 3365\n",
      "Saved deduplicated embeddings to embeddings_cache/*.\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "id": "9d7ca76416cc676c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T07:24:16.357561Z",
     "start_time": "2025-12-20T07:24:15.125488Z"
    }
   },
   "source": [
    "################################################################################\n",
    "# Block 6A - Check Class Balance (FAST - no processing needed)\n",
    "################################################################################\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# Load existing embeddings and labels\n",
    "X = np.load(EMB_FILE)\n",
    "y = np.load(LBL_FILE, allow_pickle=True)\n",
    "\n",
    "# Count samples per class\n",
    "class_counts = Counter(y)\n",
    "class_counts_sorted = sorted(class_counts.items(), key=lambda x: x[1])\n",
    "\n",
    "# Statistics\n",
    "min_samples = min(class_counts.values())\n",
    "max_samples = max(class_counts.values())\n",
    "mean_samples = np.mean(list(class_counts.values()))\n",
    "median_samples = np.median(list(class_counts.values()))\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üìä CLASS BALANCE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total classes: {len(class_counts)}\")\n",
    "print(f\"Total samples: {len(y)}\")\n",
    "print(f\"Min samples per class: {min_samples}\")\n",
    "print(f\"Max samples per class: {max_samples}\")\n",
    "print(f\"Mean samples per class: {mean_samples:.1f}\")\n",
    "print(f\"Median samples per class: {median_samples:.1f}\")\n",
    "print(f\"Imbalance ratio: {max_samples/min_samples:.2f}x\")\n",
    "\n",
    "# Define balance threshold\n",
    "BALANCE_THRESHOLD = 1.5  # If max/min > 1.5x, consider imbalanced\n",
    "IS_BALANCED = (max_samples / min_samples) <= BALANCE_THRESHOLD\n",
    "\n",
    "if IS_BALANCED:\n",
    "    print(f\"\\n‚úÖ Dataset is BALANCED (ratio {max_samples/min_samples:.2f}x ‚â§ {BALANCE_THRESHOLD}x)\")\n",
    "    print(\"   No augmentation needed!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Dataset is IMBALANCED (ratio {max_samples/min_samples:.2f}x > {BALANCE_THRESHOLD}x)\")\n",
    "    print(\"   Augmentation recommended! Run Block 6B below.\")\n",
    "\n",
    "# Show classes with fewest samples\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìâ CLASSES WITH FEWEST SAMPLES (Bottom 10)\")\n",
    "print(\"=\"*80)\n",
    "for class_name, count in class_counts_sorted[:10]:\n",
    "    print(f\"  {class_name}: {count} samples\")\n",
    "\n",
    "# Show classes with most samples\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìà CLASSES WITH MOST SAMPLES (Top 10)\")\n",
    "print(\"=\"*80)\n",
    "for class_name, count in class_counts_sorted[-10:]:\n",
    "    print(f\"  {class_name}: {count} samples\")\n",
    "\n",
    "# Visualize distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "counts = [count for _, count in class_counts_sorted]\n",
    "plt.bar(range(len(counts)), counts, color='skyblue', edgecolor='black')\n",
    "plt.axhline(y=mean_samples, color='red', linestyle='--', label=f'Mean: {mean_samples:.1f}')\n",
    "plt.axhline(y=median_samples, color='green', linestyle='--', label=f'Median: {median_samples:.1f}')\n",
    "plt.xlabel('Class Index (sorted by count)')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Samples per Class Distribution')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('class_distribution.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Distribution plot saved as: class_distribution.png\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save balance report\n",
    "balance_report = []\n",
    "for class_name, count in sorted(class_counts.items()):\n",
    "    balance_report.append({\n",
    "        'class': class_name,\n",
    "        'samples': count,\n",
    "        'percentage': f\"{count/len(y)*100:.2f}%\",\n",
    "        'status': '‚úì Good' if count >= mean_samples*0.7 else '‚ö† Low'\n",
    "    })\n",
    "\n",
    "balance_df = pd.DataFrame(balance_report)\n",
    "balance_df.to_csv('class_balance_report.csv', index=False)\n",
    "print(f\"‚úÖ Detailed balance report saved as: class_balance_report.csv\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üìä CLASS BALANCE ANALYSIS\n",
      "================================================================================\n",
      "Total classes: 21\n",
      "Total samples: 3365\n",
      "Min samples per class: 102\n",
      "Max samples per class: 213\n",
      "Mean samples per class: 160.2\n",
      "Median samples per class: 161.0\n",
      "Imbalance ratio: 2.09x\n",
      "\n",
      "‚ö†Ô∏è Dataset is IMBALANCED (ratio 2.09x > 1.5x)\n",
      "   Augmentation recommended! Run Block 6B below.\n",
      "\n",
      "================================================================================\n",
      "üìâ CLASSES WITH FEWEST SAMPLES (Bottom 10)\n",
      "================================================================================\n",
      "  pins_jeff bezos: 102 samples\n",
      "  pins_Jimmy Fallon: 113 samples\n",
      "  pins_barack obama: 119 samples\n",
      "  pins_Bill Gates: 122 samples\n",
      "  pins_Ben Affleck: 126 samples\n",
      "  pins_Emma Stone: 138 samples\n",
      "  pins_Jessica Barden: 141 samples\n",
      "  pins_Karan Kamble: 143 samples\n",
      "  pins_Elizabeth Lail: 155 samples\n",
      "  pins_Jake Mcdorman: 159 samples\n",
      "\n",
      "================================================================================\n",
      "üìà CLASSES WITH MOST SAMPLES (Top 10)\n",
      "================================================================================\n",
      "  pins_Chris Evans: 166 samples\n",
      "  pins_Jeremy Renner: 166 samples\n",
      "  pins_Jennifer Lawrence: 180 samples\n",
      "  pins_Johnny Depp: 180 samples\n",
      "  pins_Danielle Panabaker: 181 samples\n",
      "  pins_Jason Momoa: 184 samples\n",
      "  pins_barbara palvin: 196 samples\n",
      "  pins_Emilia Clarke: 209 samples\n",
      "  pins_Emma Watson: 211 samples\n",
      "  pins_Adriana Lima: 213 samples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Distribution plot saved as: class_distribution.png\n",
      "================================================================================\n",
      "‚úÖ Detailed balance report saved as: class_balance_report.csv\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "id": "21cfdfcaf1866b81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T07:24:16.566957Z",
     "start_time": "2025-12-20T07:24:16.440522Z"
    }
   },
   "source": [
    "################################################################################\n",
    "# Block 6B - Smart Augmentation (Embedding-Level) (cache-aware incremental augment)\n",
    "################################################################################\n",
    "print(\"\\n\\n\" + \"=\"*80)\n",
    "print(\"üîÑ SMART AUGMENTATION (Embedding-Level)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ---- imports ----\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import sys, os\n",
    "\n",
    "# ---- Helpers: locate CACHE_DIR (try existing variable else default) ----\n",
    "try:\n",
    "    CACHE_DIR\n",
    "except NameError:\n",
    "    CACHE_DIR = Path('embeddings_cache')\n",
    "CACHE_DIR = Path(CACHE_DIR)\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# candidate paths (try to preserve earlier names if present in workspace)\n",
    "emb_cache = CACHE_DIR / 'X_emb_augmented.npy'\n",
    "lbl_cache = CACHE_DIR / 'y_lbl_augmented.npy'\n",
    "paths_cache = CACHE_DIR / 'paths_augmented.npy'\n",
    "augmentation_report_csv = Path('augmentation_report.csv')\n",
    "\n",
    "# Try loading embeddings/labels/paths either from workspace variables or files\n",
    "def _load_var_or_file(varnames, candidates, label):\n",
    "    g = globals()\n",
    "    for n in varnames:\n",
    "        if n in g and g[n] is not None:\n",
    "            return g[n], f\"variable '{n}'\"\n",
    "    for c in candidates:\n",
    "        if c is None:\n",
    "            continue\n",
    "        p = Path(c)\n",
    "        if p.exists():\n",
    "            val = np.load(p, allow_pickle=True)\n",
    "            return val, f\"file: {p}\"\n",
    "    raise NameError(f\"{label} not found (tried vars {varnames} and files {candidates})\")\n",
    "\n",
    "# Attempt to find X, y, paths in globals or in common files\n",
    "emb_candidates = [emb_cache, 'X_emb.npy', 'X.npy', 'embeddings.npy']\n",
    "lbl_candidates = [lbl_cache, 'y_lbl.npy', 'y.npy', 'labels.npy']\n",
    "paths_candidates = [paths_cache, 'paths.npy']\n",
    "\n",
    "try:\n",
    "    X, X_source = _load_var_or_file(['X', 'X_emb', 'embeddings', 'embs'], emb_candidates, \"embeddings (X)\")\n",
    "    print(f\"‚úÖ Loaded embeddings X from {X_source}\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(str(e) + \"\\nMake sure embeddings exist in memory as X or as a file.\") from None\n",
    "\n",
    "try:\n",
    "    y, y_source = _load_var_or_file(['y', 'y_lbl', 'labels', 'y_labels'], lbl_candidates, \"labels (y)\")\n",
    "    print(f\"‚úÖ Loaded labels y from {y_source}\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(str(e) + \"\\nMake sure labels exist in memory as y or as a file.\") from None\n",
    "\n",
    "try:\n",
    "    paths, paths_source = _load_var_or_file(['paths', 'img_paths', 'paths_arr'], paths_candidates, \"paths\")\n",
    "    print(f\"‚úÖ Loaded 'paths' from {paths_source}\")\n",
    "except Exception:\n",
    "    # fallback: create dummy paths (so code runs)\n",
    "    n_items = len(y) if 'y' in globals() else len(X)\n",
    "    paths = np.array([f\"idx_{i}\" for i in range(n_items)], dtype=object)\n",
    "    print(\"‚ö†Ô∏è 'paths' not found ‚Äî created placeholder path names.\")\n",
    "\n",
    "# ---- compute current class stats (base dataset) ----\n",
    "unique_classes, counts = np.unique(y, return_counts=True)\n",
    "min_samples = int(counts.min())\n",
    "max_samples = int(counts.max())\n",
    "imb_ratio = max_samples / min_samples\n",
    "IS_BALANCED = imb_ratio <= 1.5\n",
    "\n",
    "if not IS_BALANCED:\n",
    "    print(\"‚ö†Ô∏è Your dataset is imbalanced. Proceeding with augmentation...\")\n",
    "    PROCEED_WITH_AUGMENTATION = True\n",
    "else:\n",
    "    print(\"‚úÖ Dataset is balanced. Skipping augmentation.\")\n",
    "    PROCEED_WITH_AUGMENTATION = False\n",
    "\n",
    "if PROCEED_WITH_AUGMENTATION:\n",
    "    # ---- configuration / performance ----\n",
    "    TARGET_SAMPLES = max_samples              # dynamic: balance to current max class size\n",
    "    MIN_SAMPLES_FOR_AUGMENT = 150             # informational only\n",
    "    AUG_BATCH = 128                           # batch size for synthetic generation\n",
    "    NOISE_STD = 0.01                          # gaussian noise stddev added to synthetic\n",
    "    print(f\"üéØ Target: {TARGET_SAMPLES} samples per class  (dynamic)\")\n",
    "    print(f\"üìä Current range: {min_samples} - {max_samples} samples\")\n",
    "    print(f\"üîß Will augment classes with < {TARGET_SAMPLES} samples (actual target)\")\n",
    "\n",
    "    # If augmented cache exists, load it. We will check its balance and possibly incrementally augment.\n",
    "    if emb_cache.exists() and lbl_cache.exists() and paths_cache.exists():\n",
    "        print(\"‚è±Ô∏è Augmented cache detected ‚Äî loading augmented artifacts from cache.\")\n",
    "        X_augmented = np.load(emb_cache, allow_pickle=True)\n",
    "        y_augmented = np.load(lbl_cache, allow_pickle=True)\n",
    "        paths_augmented = np.load(paths_cache, allow_pickle=True)\n",
    "\n",
    "        # Compute balance on cached augmented data\n",
    "        cached_counts = Counter(y_augmented)\n",
    "        cached_min = min(cached_counts.values())\n",
    "        cached_max = max(cached_counts.values())\n",
    "        print(f\"\\nCached augmented data range: {cached_min} - {cached_max} samples (imbalance {cached_max/cached_min:.2f}x)\")\n",
    "\n",
    "        # If cache is already fully balanced to TARGET_SAMPLES, skip. Otherwise do incremental augmentation.\n",
    "        if cached_min >= TARGET_SAMPLES and cached_max <= TARGET_SAMPLES:\n",
    "            print(\"‚úÖ Cached augmented dataset already meets TARGET_SAMPLES for all classes. No further augmentation required.\")\n",
    "        else:\n",
    "            # We'll only generate the missing samples per class to reach TARGET_SAMPLES\n",
    "            print(\"üîÅ Cached dataset still imbalanced vs TARGET_SAMPLES ‚Äî performing incremental augmentation for missing classes...\")\n",
    "            incremental_stats = []\n",
    "\n",
    "            # Build a dictionary mapping class -> current count in cached set\n",
    "            class_to_count = {c: cached_counts.get(c, 0) for c in unique_classes}\n",
    "\n",
    "            # For speed, convert X_augmented to list for append, same for labels/paths\n",
    "            X_list = list(X_augmented)\n",
    "            y_list = list(y_augmented)\n",
    "            paths_list = list(paths_augmented)\n",
    "\n",
    "            for class_name in tqdm(unique_classes, desc='Processing classes for incremental augmentation'):\n",
    "                current = class_to_count.get(class_name, 0)\n",
    "                if current >= TARGET_SAMPLES:\n",
    "                    continue  # already enough\n",
    "                needed = TARGET_SAMPLES - current\n",
    "                synthetic_count = 0\n",
    "\n",
    "                # Get originals for this class from the original X,y (not from cache) ‚Äî better variation\n",
    "                mask_orig = (y == class_name)\n",
    "                orig_embs = X[mask_orig]\n",
    "                if len(orig_embs) == 0:\n",
    "                    # if original dataset had 0, fallback to using class embeddings from cached set\n",
    "                    mask_cache = (y_augmented == class_name)\n",
    "                    orig_embs = X_augmented[mask_cache]\n",
    "                    if len(orig_embs) == 0:\n",
    "                        print(f\"‚ö†Ô∏è No originals found for class '{class_name}' in either original or cached data. Skipping.\")\n",
    "                        continue\n",
    "\n",
    "                emb_indices = np.arange(len(orig_embs))\n",
    "                synth_idx = 0\n",
    "\n",
    "                while synthetic_count < needed:\n",
    "                    batch = int(min(AUG_BATCH, needed - synthetic_count))\n",
    "\n",
    "                    if len(emb_indices) == 1:\n",
    "                        idx1 = idx2 = np.zeros(batch, dtype=int)\n",
    "                    else:\n",
    "                        idx1 = np.random.choice(emb_indices, size=batch, replace=True)\n",
    "                        idx2 = np.random.choice(emb_indices, size=batch, replace=True)\n",
    "\n",
    "                    emb1 = orig_embs[idx1]\n",
    "                    emb2 = orig_embs[idx2]\n",
    "\n",
    "                    alphas = np.random.uniform(0.3, 0.7, size=(batch, 1))\n",
    "                    synthetics = alphas * emb1 + (1 - alphas) * emb2\n",
    "                    noise = np.random.normal(0.0, NOISE_STD, size=synthetics.shape)\n",
    "                    synthetics = synthetics + noise\n",
    "\n",
    "                    norms = np.linalg.norm(synthetics, axis=1, keepdims=True)\n",
    "                    norms[norms == 0] = 1.0\n",
    "                    synthetics = synthetics / norms\n",
    "\n",
    "                    for i in range(batch):\n",
    "                        X_list.append(synthetics[i].astype('float32'))\n",
    "                        y_list.append(class_name)\n",
    "                        paths_list.append(f\"incremental_synth_{class_name}_{synth_idx}\")\n",
    "                        synth_idx += 1\n",
    "\n",
    "                    synthetic_count += batch\n",
    "\n",
    "                incremental_stats.append({\n",
    "                    'class': class_name,\n",
    "                    'original_in_cache': current,\n",
    "                    'added': synthetic_count,\n",
    "                    'new_total': current + synthetic_count\n",
    "                })\n",
    "                # update cached count for this class so subsequent checks use updated value\n",
    "                class_to_count[class_name] = current + synthetic_count\n",
    "\n",
    "            # Convert lists back to arrays\n",
    "            X_augmented = np.array(X_list, dtype='float32')\n",
    "            y_augmented = np.array(y_list, dtype=object)\n",
    "            paths_augmented = np.array(paths_list, dtype=object)\n",
    "\n",
    "            # Update augmentation report: combine previous report (if exists) with incremental report\n",
    "            if augmentation_report_csv.exists():\n",
    "                try:\n",
    "                    prev_df = pd.read_csv(augmentation_report_csv)\n",
    "                except Exception:\n",
    "                    prev_df = pd.DataFrame()\n",
    "            else:\n",
    "                prev_df = pd.DataFrame()\n",
    "\n",
    "            if incremental_stats:\n",
    "                inc_df = pd.DataFrame(incremental_stats)\n",
    "                # If prev_df has same classes, add added counts to previous synthetic; otherwise concat\n",
    "                if not prev_df.empty:\n",
    "                    prev_df = prev_df.set_index('class')\n",
    "                    inc_df = inc_df.set_index('class')\n",
    "                    for cls in inc_df.index:\n",
    "                        if cls in prev_df.index:\n",
    "                            prev_row = prev_df.loc[cls].to_dict()\n",
    "                            # update synthetic & total\n",
    "                            prev_df.at[cls, 'synthetic'] = int(prev_df.at[cls, 'synthetic']) + int(inc_df.at[cls, 'added'])\n",
    "                            prev_df.at[cls, 'total'] = int(prev_df.at[cls, 'total']) + int(inc_df.at[cls, 'added'])\n",
    "                        else:\n",
    "                            prev_df = pd.concat([prev_df, pd.DataFrame({\n",
    "                                'original': [inc_df.at[cls, 'original_in_cache']],\n",
    "                                'synthetic': [inc_df.at[cls, 'added']],\n",
    "                                'total': [inc_df.at[cls, 'new_total']]\n",
    "                            }, index=[cls])])\n",
    "                    prev_df = prev_df.reset_index().rename(columns={'index': 'class'})\n",
    "                    final_report_df = prev_df\n",
    "                else:\n",
    "                    inc_df = inc_df.reset_index().rename(columns={'index': 'class'})\n",
    "                    final_report_df = inc_df\n",
    "                final_report_df.to_csv(augmentation_report_csv, index=False)\n",
    "                print(\"\\n‚úÖ Incremental augmentation completed and augmentation_report.csv updated.\")\n",
    "                try:\n",
    "                    print(final_report_df.to_string(index=False))\n",
    "                except Exception:\n",
    "                    pass\n",
    "            else:\n",
    "                print(\"‚ÑπÔ∏è No incremental augmentation was needed (cache already met TARGET_SAMPLES).\")\n",
    "\n",
    "            # Save updated caches\n",
    "            np.save(emb_cache, X_augmented)\n",
    "            np.save(lbl_cache, y_augmented)\n",
    "            np.save(paths_cache, paths_augmented)\n",
    "            print(\"\\n‚úÖ Cache files updated with incremental augmentations.\")\n",
    "\n",
    "    else:\n",
    "        # No cache exists: perform full augmentation up to TARGET_SAMPLES (same approach as incremental)\n",
    "        print(\"üîÑ No augmented cache found ‚Äî generating full augmented dataset up to TARGET_SAMPLES...\")\n",
    "        X_list = []\n",
    "        y_list = []\n",
    "        paths_list = []\n",
    "        augmentation_stats = []\n",
    "\n",
    "        for class_name in tqdm(unique_classes, desc='Processing classes'):\n",
    "            mask_orig = (y == class_name)\n",
    "            orig_embs = X[mask_orig]\n",
    "            orig_paths = np.array(paths)[mask_orig]\n",
    "            current_count = len(orig_embs)\n",
    "\n",
    "            # add originals\n",
    "            X_list.extend(orig_embs)\n",
    "            y_list.extend([class_name] * current_count)\n",
    "            paths_list.extend(orig_paths.tolist())\n",
    "\n",
    "            if current_count < TARGET_SAMPLES:\n",
    "                needed_total = TARGET_SAMPLES - current_count\n",
    "                synthetic_count = 0\n",
    "                emb_indices = np.arange(len(orig_embs))\n",
    "                syn_idx = 0\n",
    "\n",
    "                if len(emb_indices) == 0:\n",
    "                    print(f\"‚ö†Ô∏è Class '{class_name}' has 0 originals ‚Äî skipping.\")\n",
    "                    continue\n",
    "\n",
    "                while synthetic_count < needed_total:\n",
    "                    batch = int(min(AUG_BATCH, needed_total - synthetic_count))\n",
    "\n",
    "                    if len(emb_indices) == 1:\n",
    "                        idx1 = idx2 = np.zeros(batch, dtype=int)\n",
    "                    else:\n",
    "                        idx1 = np.random.choice(emb_indices, size=batch, replace=True)\n",
    "                        idx2 = np.random.choice(emb_indices, size=batch, replace=True)\n",
    "\n",
    "                    emb1 = orig_embs[idx1]\n",
    "                    emb2 = orig_embs[idx2]\n",
    "\n",
    "                    alphas = np.random.uniform(0.3, 0.7, size=(batch, 1))\n",
    "                    synthetics = alphas * emb1 + (1 - alphas) * emb2\n",
    "                    noise = np.random.normal(0.0, NOISE_STD, size=synthetics.shape)\n",
    "                    synthetics = synthetics + noise\n",
    "\n",
    "                    norms = np.linalg.norm(synthetics, axis=1, keepdims=True)\n",
    "                    norms[norms == 0] = 1.0\n",
    "                    synthetics = synthetics / norms\n",
    "\n",
    "                    for i in range(batch):\n",
    "                        X_list.append(synthetics[i].astype('float32'))\n",
    "                        y_list.append(class_name)\n",
    "                        paths_list.append(f\"synthetic_{class_name}_{syn_idx}\")\n",
    "                        syn_idx += 1\n",
    "\n",
    "                    synthetic_count += batch\n",
    "\n",
    "                augmentation_stats.append({\n",
    "                    'class': class_name,\n",
    "                    'original': current_count,\n",
    "                    'synthetic': synthetic_count,\n",
    "                    'total': current_count + synthetic_count\n",
    "                })\n",
    "\n",
    "        # convert and save\n",
    "        X_augmented = np.array(X_list, dtype='float32')\n",
    "        y_augmented = np.array(y_list, dtype=object)\n",
    "        paths_augmented = np.array(paths_list, dtype=object)\n",
    "\n",
    "        np.save(emb_cache, X_augmented)\n",
    "        np.save(lbl_cache, y_augmented)\n",
    "        np.save(paths_cache, paths_augmented)\n",
    "\n",
    "        if augmentation_stats:\n",
    "            aug_df = pd.DataFrame(augmentation_stats)\n",
    "            aug_df.to_csv(augmentation_report_csv, index=False)\n",
    "            print(\"\\n‚úÖ Augmentation complete and report saved.\")\n",
    "            print(aug_df.to_string(index=False))\n",
    "        else:\n",
    "            print(\"\\n‚ÑπÔ∏è No augmentation stats recorded (unexpected if dataset was imbalanced).\")\n",
    "\n",
    "    # ---- report final balance status ----\n",
    "    new_counts = Counter(np.load(lbl_cache, allow_pickle=True))\n",
    "    new_min = min(new_counts.values())\n",
    "    new_max = max(new_counts.values())\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä NEW BALANCE STATUS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Min samples per class: {new_min}\")\n",
    "    print(f\"Max samples per class: {new_max}\")\n",
    "    print(f\"New imbalance ratio: {new_max/new_min:.2f}x\")\n",
    "\n",
    "    if new_max / new_min <= 1.5:\n",
    "        print(\"‚úÖ Dataset is now BALANCED!\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Still some imbalance (consider increasing TARGET_SAMPLES or re-running augmentation)\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìÅ AUGMENTED FILES SAVED:\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"‚úÖ {emb_cache}\")\n",
    "    print(f\"‚úÖ {lbl_cache}\")\n",
    "    print(f\"‚úÖ {paths_cache}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚ö†Ô∏è IMPORTANT: Update Block 7 (training) to use augmented files:\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"Change these lines in Block 7:\")\n",
    "    print(\"  FROM:\")\n",
    "    print(\"    EMB_SRC = EMB_FILE\")\n",
    "    print(\"    LBL_SRC = LBL_FILE\")\n",
    "    print(\"  TO:\")\n",
    "    print(\"    EMB_SRC = CACHE_DIR / 'X_emb_augmented.npy'\")\n",
    "    print(\"    LBL_SRC = CACHE_DIR / 'y_lbl_augmented.npy'\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚úÖ No augmentation performed. Dataset is already balanced!\")\n",
    "    print(\"   You can proceed directly to Block 7 (training).\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "================================================================================\n",
      "üîÑ SMART AUGMENTATION (Embedding-Level)\n",
      "================================================================================\n",
      "‚úÖ Loaded embeddings X from variable 'X'\n",
      "‚úÖ Loaded labels y from variable 'y'\n",
      "‚úÖ Loaded 'paths' from variable 'paths'\n",
      "‚ö†Ô∏è Your dataset is imbalanced. Proceeding with augmentation...\n",
      "üéØ Target: 213 samples per class  (dynamic)\n",
      "üìä Current range: 102 - 213 samples\n",
      "üîß Will augment classes with < 213 samples (actual target)\n",
      "‚è±Ô∏è Augmented cache detected ‚Äî loading augmented artifacts from cache.\n",
      "\n",
      "Cached augmented data range: 213 - 213 samples (imbalance 1.00x)\n",
      "‚úÖ Cached augmented dataset already meets TARGET_SAMPLES for all classes. No further augmentation required.\n",
      "\n",
      "================================================================================\n",
      "üìä NEW BALANCE STATUS\n",
      "================================================================================\n",
      "Min samples per class: 213\n",
      "Max samples per class: 213\n",
      "New imbalance ratio: 1.00x\n",
      "‚úÖ Dataset is now BALANCED!\n",
      "\n",
      "================================================================================\n",
      "üìÅ AUGMENTED FILES SAVED:\n",
      "================================================================================\n",
      "‚úÖ embeddings_cache\\X_emb_augmented.npy\n",
      "‚úÖ embeddings_cache\\y_lbl_augmented.npy\n",
      "‚úÖ embeddings_cache\\paths_augmented.npy\n",
      "\n",
      "================================================================================\n",
      "‚ö†Ô∏è IMPORTANT: Update Block 7 (training) to use augmented files:\n",
      "================================================================================\n",
      "Change these lines in Block 7:\n",
      "  FROM:\n",
      "    EMB_SRC = EMB_FILE\n",
      "    LBL_SRC = LBL_FILE\n",
      "  TO:\n",
      "    EMB_SRC = CACHE_DIR / 'X_emb_augmented.npy'\n",
      "    LBL_SRC = CACHE_DIR / 'y_lbl_augmented.npy'\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "id": "59353f38bcf30c74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T07:43:32.184275Z",
     "start_time": "2025-12-20T07:43:28.059003Z"
    }
   },
   "source": [
    "# Block 7 ‚Äî train classifier (SVM)\n",
    "from sklearn.preprocessing import LabelEncoder, Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# choose embeddings source (deduped if you created them)\n",
    "EMB_SRC = CACHE_DIR / 'X_emb_augmented.npy'\n",
    "LBL_SRC = CACHE_DIR / 'y_lbl_augmented.npy'\n",
    "\n",
    "X = np.load(EMB_SRC)\n",
    "y = np.load(LBL_SRC, allow_pickle=True)\n",
    "print(\"Loaded embeddings:\", X.shape)\n",
    "\n",
    "le = LabelEncoder().fit(y); y_enc = le.transform(y)\n",
    "norm = Normalizer('l2'); Xn = norm.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xn, y_enc, stratify=y_enc, test_size=0.15, random_state=42)\n",
    "print(\"Train/test:\", X_train.shape, X_test.shape)\n",
    "\n",
    "clf = SVC(kernel='linear', probability=True, class_weight='balanced')\n",
    "t0 = time.time(); clf.fit(X_train, y_train)\n",
    "print(\"Trained SVM in {:.1f}s\".format(time.time()-t0))\n",
    "\n",
    "# Save classifier with consistent keys\n",
    "with open(CLF_FILE, 'wb') as f:\n",
    "    pickle.dump({'clf': clf, 'le': le, 'norm': norm, 'X_test': X_test, 'y_test': y_test}, f)\n",
    "print(\"Saved classifier to\", CLF_FILE)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings: (4473, 512)\n",
      "Train/test: (3802, 512) (671, 512)\n",
      "Trained SVM in 4.0s\n",
      "Saved classifier to embeddings_cache\\svc_model_retrained.pkl\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "id": "41df414e6464bafd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T07:53:36.138759Z",
     "start_time": "2025-12-20T07:52:58.513523Z"
    }
   },
   "source": [
    "# Block 8 ‚Äî evaluation: classification report, confusion matrix, 5-fold CV, centroid baseline, threshold\n",
    "import pickle, numpy as np, matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# load saved classifier\n",
    "obj = pickle.load(open(CLF_FILE, 'rb'))\n",
    "clf = obj['clf']; le = obj['le']; norm = obj['norm']\n",
    "X_test = obj['X_test']; y_test = obj['y_test']\n",
    "\n",
    "# report\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred).astype(float)\n",
    "cmn = cm / cm.sum(axis=1)[:, None]\n",
    "plt.figure(figsize=(8,8)); plt.imshow(cmn); plt.title('Normalized confusion matrix'); plt.colorbar(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# 5-fold CV on full dataset\n",
    "X_all = np.load(EMB_FILE); y_all = np.load(LBL_FILE, allow_pickle=True)\n",
    "y_all_enc = le.transform(y_all); Xn_all = norm.transform(X_all)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accs = []\n",
    "for tr, te in skf.split(Xn_all, y_all_enc):\n",
    "    clf.fit(Xn_all[tr], y_all_enc[tr])\n",
    "    accs.append(clf.score(Xn_all[te], y_all_enc[te]))\n",
    "print(\"5-fold CV: mean={:.4f} std={:.4f}\".format(np.mean(accs), np.std(accs)))\n",
    "\n",
    "# centroid baseline\n",
    "Xn_norm = normalize(X_all, axis=1)\n",
    "centroids = {c: Xn_norm[y_all_enc==c].mean(axis=0) for c in np.unique(y_all_enc)}\n",
    "# save centroids and classes for lightweight inference\n",
    "centroid_matrix = np.vstack([centroids[c] for c in sorted(centroids.keys())])\n",
    "classes_order = np.array([le.classes_[c] for c in sorted(centroids.keys())])\n",
    "np.save(CENTROIDS_FILE, centroid_matrix)\n",
    "np.save(CLASSES_FILE, classes_order)\n",
    "print(\"Saved centroids to\", CENTROIDS_FILE, \"and classes to\", CLASSES_FILE)\n",
    "\n",
    "# centroid accuracy on same test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "_, X_test_c, _, y_test_c = train_test_split(Xn_norm, y_all_enc, stratify=y_all_enc, test_size=0.15, random_state=42)\n",
    "def predict_centroid(emb):\n",
    "    emb = emb / np.linalg.norm(emb)\n",
    "    sims = centroid_matrix.dot(emb)\n",
    "    return sims.argmax(), sims.max()\n",
    "y_cent = [predict_centroid(e)[0] for e in X_test_c]\n",
    "print(\"Centroid baseline accuracy:\", accuracy_score(y_test_c, y_cent))\n",
    "\n",
    "# Open-set threshold suggestion: compute genuine vs impostor cosine scores on validation set\n",
    "# Build per-class centroid from training portion and compute scores: simple approach using split\n",
    "tr, val = next(StratifiedKFold(n_splits=5, shuffle=True, random_state=42).split(Xn_all, y_all_enc))\n",
    "# compute centroids on tr\n",
    "centroids_tr = {c: Xn_all[tr][y_all_enc[tr]==c].mean(axis=0) for c in np.unique(y_all_enc)}\n",
    "# compute genuine scores and impostor scores on val set\n",
    "genuine_scores = []\n",
    "impostor_scores = []\n",
    "for i, emb in enumerate(Xn_all[val]):\n",
    "    label = y_all_enc[val][i]\n",
    "    emb_norm = emb / np.linalg.norm(emb)\n",
    "    sims = [emb_norm.dot(centroids_tr[c]) for c in centroids_tr]\n",
    "    # genuine score = sim with true class centroid\n",
    "    genuine_scores.append(emb_norm.dot(centroids_tr[label]))\n",
    "    # impostor score = max sim to any other class centroid\n",
    "    impostor_scores.append(max([s for c,s in zip(centroids_tr.keys(), sims) if c != label]))\n",
    "\n",
    "genuine_scores = np.array(genuine_scores); impostor_scores = np.array(impostor_scores)\n",
    "# compute ROC between genuine and impostor by labeling genuine=1, impostor=0 (stack arrays)\n",
    "labels_scores = np.concatenate([np.ones_like(genuine_scores), np.zeros_like(impostor_scores)])\n",
    "scores = np.concatenate([genuine_scores, impostor_scores])\n",
    "fpr, tpr, thresholds = roc_curve(labels_scores, scores)\n",
    "# pick threshold where tpr ~ 0.95 or where (tpr-fpr) is maximized\n",
    "idx = (np.abs(tpr - 0.95)).argmin()\n",
    "suggested_thresh = thresholds[idx]\n",
    "print(f\"Suggested cosine threshold for open-set (approx TPR=0.95): {suggested_thresh:.4f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "      pins_Adriana Lima       1.00      1.00      1.00        31\n",
      "       pins_Ben Affleck       1.00      1.00      1.00        32\n",
      "        pins_Bill Gates       1.00      1.00      1.00        32\n",
      "       pins_Chris Evans       1.00      1.00      1.00        32\n",
      "pins_Danielle Panabaker       1.00      1.00      1.00        32\n",
      "      pins_Eliza Taylor       1.00      1.00      1.00        32\n",
      "    pins_Elizabeth Lail       1.00      1.00      1.00        32\n",
      "     pins_Emilia Clarke       1.00      1.00      1.00        32\n",
      "        pins_Emma Stone       1.00      1.00      1.00        32\n",
      "       pins_Emma Watson       1.00      0.97      0.98        32\n",
      "     pins_Jake Mcdorman       1.00      1.00      1.00        32\n",
      "       pins_Jason Momoa       1.00      1.00      1.00        32\n",
      " pins_Jennifer Lawrence       1.00      1.00      1.00        32\n",
      "     pins_Jeremy Renner       1.00      1.00      1.00        32\n",
      "    pins_Jessica Barden       1.00      0.97      0.98        32\n",
      "      pins_Jimmy Fallon       0.97      1.00      0.98        32\n",
      "       pins_Johnny Depp       1.00      1.00      1.00        32\n",
      "      pins_Karan Kamble       1.00      1.00      1.00        32\n",
      "      pins_barack obama       1.00      1.00      1.00        32\n",
      "    pins_barbara palvin       0.97      1.00      0.98        32\n",
      "        pins_jeff bezos       1.00      1.00      1.00        32\n",
      "\n",
      "               accuracy                           1.00       671\n",
      "              macro avg       1.00      1.00      1.00       671\n",
      "           weighted avg       1.00      1.00      1.00       671\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold CV: mean=0.9967 std=0.0022\n",
      "Saved centroids to embeddings_cache\\centroids.npy and classes to embeddings_cache\\classes.npy\n",
      "Centroid baseline accuracy: 0.9900990099009901\n",
      "Suggested cosine threshold for open-set (approx TPR=0.95): 0.4614\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "id": "ef136c659630fb96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T07:54:13.162858Z",
     "start_time": "2025-12-20T07:54:13.124891Z"
    }
   },
   "source": [
    "# Block 9.1 ‚Äî inference helpers (SVM and centroid)\n",
    "import numpy as np, pickle, cv2, torch\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# load artifacts\n",
    "obj = pickle.load(open(CLF_FILE, 'rb'))\n",
    "clf = obj['clf']; le = obj['le']; norm = obj['norm']\n",
    "centroid_matrix = np.load(CENTROIDS_FILE)\n",
    "classes_order = np.load(CLASSES_FILE)\n",
    "\n",
    "def predict_with_svm(image_path, top_k=3):\n",
    "    img = cv2.cvtColor(cv2.imread(str(image_path)), cv2.COLOR_BGR2RGB)\n",
    "    face = mtcnn(img)\n",
    "    if face is None:\n",
    "        return None\n",
    "    if face.dim()==3: face = face.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        emb = resnet(face).cpu().numpy().reshape(1,-1)\n",
    "    emb = norm.transform(emb)\n",
    "    probs = clf.predict_proba(emb)[0]\n",
    "    idx = probs.argsort()[::-1][:top_k]\n",
    "    return [(le.classes_[i], float(probs[i])) for i in idx]\n",
    "\n",
    "def predict_with_centroid(image_path, top_k=3):\n",
    "    img = cv2.cvtColor(cv2.imread(str(image_path)), cv2.COLOR_BGR2RGB)\n",
    "    face = mtcnn(img)\n",
    "    if face is None:\n",
    "        return None\n",
    "    if face.dim()==3: face = face.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        emb = resnet(face).cpu().numpy().reshape(-1)\n",
    "    emb = emb / np.linalg.norm(emb)\n",
    "    sims = centroid_matrix.dot(emb)\n",
    "    idx = sims.argsort()[::-1][:top_k]\n",
    "    return [(classes_order[i], float(sims[i])) for i in idx]\n",
    "\n",
    "print(\"Inference helpers ready. Example:\")\n",
    "# print(predict_with_centroid('path/to/example.jpg'))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference helpers ready. Example:\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "id": "48455e1a9b4a10b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T07:54:19.043785Z",
     "start_time": "2025-12-20T07:54:18.900299Z"
    }
   },
   "source": [
    "# Block 9.2\n",
    "\n",
    "# centroid baseline\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# FIX: Added allow_pickle=True to handle string labels in y_lbl.npy\n",
    "X = np.load('./embeddings_cache/X_emb.npy', allow_pickle=True)\n",
    "y = np.load('./embeddings_cache/y_lbl.npy', allow_pickle=True)\n",
    "\n",
    "le = LabelEncoder().fit(y)\n",
    "y_enc = le.transform(y)\n",
    "Xn = normalize(X, axis=1)\n",
    "\n",
    "# Calculate centroids for each class\n",
    "centroids = {c: Xn[y_enc==c].mean(axis=0) for c in np.unique(y_enc)}\n",
    "\n",
    "def predict_centroid(emb):\n",
    "    # Normalize embedding for cosine similarity\n",
    "    norm = np.linalg.norm(emb)\n",
    "    if norm == 0:\n",
    "        return 0\n",
    "    emb = emb / norm\n",
    "    # Calculate dot product (similarity) with each centroid\n",
    "    sims = [(c, emb.dot(centroids[c])) for c in centroids]\n",
    "    return max(sims, key=lambda x: x[1])[0]\n",
    "\n",
    "# Ensure X_test and y_test exist from your previous split block\n",
    "try:\n",
    "    y_cent = [predict_centroid(e) for e in X_test]\n",
    "    print(\"Centroid accuracy on test:\", accuracy_score(y_test, y_cent))\n",
    "except NameError:\n",
    "    print(\"Error: X_test or y_test not found. Please run the cell where you split your data first.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroid accuracy on test: 0.9955290611028316\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "id": "297a7c1f-a897-4d46-98ea-4fbcaff81f8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T08:16:54.268865Z",
     "start_time": "2025-12-20T07:54:25.492815Z"
    }
   },
   "source": [
    "# Block 10 - Predict on images and generate detailed CSV report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# ---------- EDIT THIS: Path to folder containing images to predict ----------\n",
    "PREDICT_DIR = \"data/pins_face_recognition\"  # << CHANGE THIS to your test images folder\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "# Output CSV paths\n",
    "OUTPUT_CSV = \"predictions_results.csv\"\n",
    "OUTPUT_SUMMARY_CSV = \"predictions_summary.csv\"\n",
    "\n",
    "# Load trained model and artifacts\n",
    "print(\"Loading trained model...\")\n",
    "obj = pickle.load(open(CLF_FILE, 'rb'))\n",
    "clf = obj['clf']\n",
    "le = obj['le']\n",
    "norm = obj['norm']\n",
    "print(f\"‚úÖ Model loaded. Can recognize {len(le.classes_)} classes\")\n",
    "\n",
    "# Get all image files\n",
    "PREDICT_PATH = Path(PREDICT_DIR)\n",
    "image_paths = [str(p) for p in sorted(PREDICT_PATH.rglob('*')) if p.suffix.lower() in EXTS]\n",
    "print(f\"Found {len(image_paths)} images in {PREDICT_DIR}\")\n",
    "\n",
    "if len(image_paths) == 0:\n",
    "    print(\"‚ö†Ô∏è No images found! Check PREDICT_DIR path.\")\n",
    "else:\n",
    "    # Prepare results storage\n",
    "    results = []\n",
    "    failed_images = []\n",
    "\n",
    "    print(\"\\nProcessing images...\")\n",
    "    for img_path in tqdm(image_paths, desc='Predicting'):\n",
    "        try:\n",
    "            # Load and process image\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "            # Resize if too large (speed optimization)\n",
    "            w, h = img.size\n",
    "            max_side = 640\n",
    "            if max(w, h) > max_side:\n",
    "                scale = max_side / max(w, h)\n",
    "                img = img.resize((int(w*scale), int(h*scale)), Image.BILINEAR)\n",
    "\n",
    "            # Detect face\n",
    "            face = mtcnn(img)\n",
    "\n",
    "            if face is None:\n",
    "                failed_images.append((img_path, \"No face detected\"))\n",
    "                continue\n",
    "\n",
    "            # Ensure correct dimensions\n",
    "            if face.dim() == 3:\n",
    "                face = face.unsqueeze(0)\n",
    "\n",
    "            # Get embedding\n",
    "            with torch.no_grad():\n",
    "                emb = resnet(face).cpu().numpy().reshape(1, -1)\n",
    "\n",
    "            # Normalize\n",
    "            emb_norm = norm.transform(emb)\n",
    "\n",
    "            # Predict\n",
    "            pred_class = clf.predict(emb_norm)[0]\n",
    "            pred_label = le.inverse_transform([pred_class])[0]\n",
    "\n",
    "            # Get confidence (probability)\n",
    "            proba = clf.predict_proba(emb_norm)[0]\n",
    "            confidence = float(proba[pred_class])\n",
    "\n",
    "            # Get top 3 predictions\n",
    "            top3_idx = proba.argsort()[::-1][:3]\n",
    "            top3_labels = le.inverse_transform(top3_idx)\n",
    "            top3_probs = proba[top3_idx]\n",
    "\n",
    "            # Get actual label (from parent folder name)\n",
    "            actual_label = Path(img_path).parent.name\n",
    "\n",
    "            # Check if correct\n",
    "            is_correct = (actual_label == pred_label)\n",
    "\n",
    "            # Store result\n",
    "            results.append({\n",
    "                'image_path': img_path,\n",
    "                'filename': Path(img_path).name,\n",
    "                'actual': actual_label,\n",
    "                'predicted': pred_label,\n",
    "                'confidence': confidence,\n",
    "                'correct': is_correct,\n",
    "                'status': 'CORRECT ‚úì' if is_correct else 'WRONG ‚úó',\n",
    "                'top1': top3_labels[0],\n",
    "                'top1_conf': float(top3_probs[0]),\n",
    "                'top2': top3_labels[1] if len(top3_labels) > 1 else '',\n",
    "                'top2_conf': float(top3_probs[1]) if len(top3_probs) > 1 else 0.0,\n",
    "                'top3': top3_labels[2] if len(top3_labels) > 2 else '',\n",
    "                'top3_conf': float(top3_probs[2]) if len(top3_probs) > 2 else 0.0\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            failed_images.append((img_path, str(e)))\n",
    "\n",
    "    # Create DataFrame\n",
    "    if results:\n",
    "        results_df = pd.DataFrame(results)\n",
    "\n",
    "        # Sort: Correct predictions first (sorted by confidence desc), then wrong predictions\n",
    "        results_df_sorted = pd.concat([\n",
    "            results_df[results_df['correct']].sort_values('confidence', ascending=False),\n",
    "            results_df[~results_df['correct']].sort_values('confidence', ascending=False)\n",
    "        ])\n",
    "\n",
    "        # Save complete results to CSV\n",
    "        results_df_sorted.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "        # Calculate statistics\n",
    "        total_images = len(results)\n",
    "        correct_count = results_df['correct'].sum()\n",
    "        wrong_count = total_images - correct_count\n",
    "        accuracy = correct_count / total_images if total_images > 0 else 0\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üìä PREDICTION SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"‚úÖ Total images processed: {total_images}\")\n",
    "        print(f\"‚úÖ Correct predictions: {correct_count} ({correct_count/total_images*100:.2f}%)\")\n",
    "        print(f\"‚ùå Wrong predictions: {wrong_count} ({wrong_count/total_images*100:.2f}%)\")\n",
    "        print(f\"üìä Overall Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "        print(f\"üìä Average confidence: {results_df['confidence'].mean():.4f}\")\n",
    "        print(f\"‚ùå Failed to process: {len(failed_images)} images\")\n",
    "\n",
    "        # Per-class accuracy summary\n",
    "        class_summary = results_df.groupby('actual').agg({\n",
    "            'correct': ['sum', 'count', 'mean']\n",
    "        }).reset_index()\n",
    "        class_summary.columns = ['class_name', 'correct_count', 'total_count', 'accuracy']\n",
    "        class_summary['wrong_count'] = class_summary['total_count'] - class_summary['correct_count']\n",
    "        class_summary = class_summary.sort_values('accuracy', ascending=False)\n",
    "\n",
    "        # Save class summary\n",
    "        class_summary.to_csv(OUTPUT_SUMMARY_CSV, index=False)\n",
    "\n",
    "        # Show wrong predictions details\n",
    "        wrong_predictions = results_df[~results_df['correct']].copy()\n",
    "\n",
    "        if len(wrong_predictions) > 0:\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(f\"‚ùå WRONG PREDICTIONS DETAILS ({len(wrong_predictions)} total)\")\n",
    "            print(\"=\"*80)\n",
    "\n",
    "            # Group wrong predictions by actual class\n",
    "            wrong_by_class = wrong_predictions.groupby('actual').agg({\n",
    "                'filename': 'count',\n",
    "                'predicted': lambda x: ', '.join(x.value_counts().head(3).index.tolist())\n",
    "            }).reset_index()\n",
    "            wrong_by_class.columns = ['actual_class', 'wrong_count', 'predicted_as']\n",
    "            wrong_by_class = wrong_by_class.sort_values('wrong_count', ascending=False)\n",
    "\n",
    "            print(\"\\nClasses with wrong predictions:\")\n",
    "            print(wrong_by_class.to_string(index=False))\n",
    "\n",
    "            print(\"\\n\" + \"-\"*80)\n",
    "            print(\"Individual wrong predictions (showing first 20):\")\n",
    "            print(\"-\"*80)\n",
    "            wrong_display = wrong_predictions[['filename', 'actual', 'predicted', 'confidence']].head(20)\n",
    "            for idx, row in wrong_display.iterrows():\n",
    "                print(f\"  ‚Ä¢ {row['filename']}\")\n",
    "                print(f\"    Actual: {row['actual']} ‚Üí Predicted: {row['predicted']} (confidence: {row['confidence']:.3f})\")\n",
    "\n",
    "            if len(wrong_predictions) > 20:\n",
    "                print(f\"\\n  ... and {len(wrong_predictions)-20} more wrong predictions (see CSV for details)\")\n",
    "        else:\n",
    "            print(\"\\nüéâ NO WRONG PREDICTIONS! Perfect accuracy!\")\n",
    "\n",
    "        # Show classes with perfect accuracy\n",
    "        perfect_classes = class_summary[class_summary['accuracy'] == 1.0]\n",
    "        if len(perfect_classes) > 0:\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(f\"üéØ CLASSES WITH 100% ACCURACY ({len(perfect_classes)} classes)\")\n",
    "            print(\"=\"*80)\n",
    "            print(perfect_classes[['class_name', 'total_count']].head(20).to_string(index=False))\n",
    "            if len(perfect_classes) > 20:\n",
    "                print(f\"... and {len(perfect_classes)-20} more classes\")\n",
    "\n",
    "        # Show classes with lowest accuracy\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"‚ö†Ô∏è CLASSES WITH LOWEST ACCURACY (Bottom 10)\")\n",
    "        print(\"=\"*80)\n",
    "        print(class_summary[['class_name', 'correct_count', 'wrong_count', 'total_count', 'accuracy']].tail(10).to_string(index=False))\n",
    "\n",
    "        # Show correct predictions sample\n",
    "        correct_predictions = results_df[results_df['correct']]\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"‚úÖ CORRECT PREDICTIONS SAMPLE (showing 10 of {len(correct_predictions)})\")\n",
    "        print(\"=\"*80)\n",
    "        correct_display = correct_predictions[['filename', 'actual', 'confidence']].head(10)\n",
    "        for idx, row in correct_display.iterrows():\n",
    "            print(f\"  ‚úì {row['filename']}: {row['actual']} (confidence: {row['confidence']:.3f})\")\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üìÅ OUTPUT FILES SAVED:\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"‚úÖ {OUTPUT_CSV}\")\n",
    "        print(f\"   ‚Üí All predictions sorted (correct first, then wrong)\")\n",
    "        print(f\"   ‚Üí Columns: filename, actual, predicted, confidence, status, top3\")\n",
    "        print(f\"\\n‚úÖ {OUTPUT_SUMMARY_CSV}\")\n",
    "        print(f\"   ‚Üí Per-class accuracy summary\")\n",
    "        print(f\"   ‚Üí Columns: class_name, correct_count, wrong_count, total_count, accuracy\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "    # Show failed images\n",
    "    if failed_images:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"‚ùå FAILED TO PROCESS ({len(failed_images)} images)\")\n",
    "        print(\"=\"*80)\n",
    "        for path, reason in failed_images[:20]:\n",
    "            print(f\"  ‚Ä¢ {Path(path).name}: {reason}\")\n",
    "        if len(failed_images) > 20:\n",
    "            print(f\"  ... and {len(failed_images)-20} more\")\n",
    "\n",
    "        # Save failed images list\n",
    "        failed_df = pd.DataFrame(failed_images, columns=['image_path', 'error'])\n",
    "        failed_df.to_csv('failed_predictions.csv', index=False)\n",
    "        print(f\"\\n‚úÖ Failed images list saved to: failed_predictions.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ PROCESSING COMPLETE!\")\n",
    "print(\"=\"*80)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model...\n",
      "‚úÖ Model loaded. Can recognize 21 classes\n",
      "Found 3365 images in data/pins_face_recognition\n",
      "\n",
      "Processing images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3365/3365 [22:27<00:00,  2.50it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìä PREDICTION SUMMARY\n",
      "================================================================================\n",
      "‚úÖ Total images processed: 3351\n",
      "‚úÖ Correct predictions: 3348 (99.91%)\n",
      "‚ùå Wrong predictions: 3 (0.09%)\n",
      "üìä Overall Accuracy: 0.9991 (99.91%)\n",
      "üìä Average confidence: 0.9404\n",
      "‚ùå Failed to process: 14 images\n",
      "\n",
      "================================================================================\n",
      "‚ùå WRONG PREDICTIONS DETAILS (3 total)\n",
      "================================================================================\n",
      "\n",
      "Classes with wrong predictions:\n",
      "       actual_class  wrong_count                               predicted_as\n",
      "pins_Jessica Barden            2 pins_Jimmy Fallon, pins_Danielle Panabaker\n",
      "   pins_Emma Watson            1                        pins_barbara palvin\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Individual wrong predictions (showing first 20):\n",
      "--------------------------------------------------------------------------------\n",
      "  ‚Ä¢ Emma Watson186_1922.jpg\n",
      "    Actual: pins_Emma Watson ‚Üí Predicted: pins_barbara palvin (confidence: 0.265)\n",
      "  ‚Ä¢ Jessica Barden211_1449.jpg\n",
      "    Actual: pins_Jessica Barden ‚Üí Predicted: pins_Jimmy Fallon (confidence: 0.301)\n",
      "  ‚Ä¢ Jessica Barden34_1478.jpg\n",
      "    Actual: pins_Jessica Barden ‚Üí Predicted: pins_Danielle Panabaker (confidence: 0.220)\n",
      "\n",
      "================================================================================\n",
      "üéØ CLASSES WITH 100% ACCURACY (19 classes)\n",
      "================================================================================\n",
      "             class_name  total_count\n",
      "      pins_Adriana Lima          213\n",
      "       pins_Ben Affleck          126\n",
      "        pins_Bill Gates          122\n",
      "       pins_Chris Evans          166\n",
      "pins_Danielle Panabaker          181\n",
      "      pins_Eliza Taylor          161\n",
      "    pins_Elizabeth Lail          155\n",
      "     pins_Emilia Clarke          209\n",
      "        pins_Emma Stone          138\n",
      "     pins_Jake Mcdorman          159\n",
      "       pins_Jason Momoa          184\n",
      " pins_Jennifer Lawrence          180\n",
      "     pins_Jeremy Renner          166\n",
      "    pins_barbara palvin          196\n",
      "      pins_Jimmy Fallon          113\n",
      "       pins_Johnny Depp          180\n",
      "      pins_Karan Kamble          129\n",
      "        pins_jeff bezos          102\n",
      "      pins_barack obama          119\n",
      "\n",
      "================================================================================\n",
      "‚ö†Ô∏è CLASSES WITH LOWEST ACCURACY (Bottom 10)\n",
      "================================================================================\n",
      "            class_name  correct_count  wrong_count  total_count  accuracy\n",
      "pins_Jennifer Lawrence            180            0          180  1.000000\n",
      "    pins_Jeremy Renner            166            0          166  1.000000\n",
      "   pins_barbara palvin            196            0          196  1.000000\n",
      "     pins_Jimmy Fallon            113            0          113  1.000000\n",
      "      pins_Johnny Depp            180            0          180  1.000000\n",
      "     pins_Karan Kamble            129            0          129  1.000000\n",
      "       pins_jeff bezos            102            0          102  1.000000\n",
      "     pins_barack obama            119            0          119  1.000000\n",
      "      pins_Emma Watson            210            1          211  0.995261\n",
      "   pins_Jessica Barden            139            2          141  0.985816\n",
      "\n",
      "================================================================================\n",
      "‚úÖ CORRECT PREDICTIONS SAMPLE (showing 10 of 3348)\n",
      "================================================================================\n",
      "  ‚úì Adriana Lima0_0.jpg: pins_Adriana Lima (confidence: 0.922)\n",
      "  ‚úì Adriana Lima101_3.jpg: pins_Adriana Lima (confidence: 0.981)\n",
      "  ‚úì Adriana Lima102_4.jpg: pins_Adriana Lima (confidence: 0.936)\n",
      "  ‚úì Adriana Lima103_5.jpg: pins_Adriana Lima (confidence: 0.918)\n",
      "  ‚úì Adriana Lima104_6.jpg: pins_Adriana Lima (confidence: 0.959)\n",
      "  ‚úì Adriana Lima105_7.jpg: pins_Adriana Lima (confidence: 0.918)\n",
      "  ‚úì Adriana Lima106_8.jpg: pins_Adriana Lima (confidence: 0.945)\n",
      "  ‚úì Adriana Lima107_9.jpg: pins_Adriana Lima (confidence: 0.960)\n",
      "  ‚úì Adriana Lima108_10.jpg: pins_Adriana Lima (confidence: 0.963)\n",
      "  ‚úì Adriana Lima109_11.jpg: pins_Adriana Lima (confidence: 0.822)\n",
      "\n",
      "================================================================================\n",
      "üìÅ OUTPUT FILES SAVED:\n",
      "================================================================================\n",
      "‚úÖ predictions_results.csv\n",
      "   ‚Üí All predictions sorted (correct first, then wrong)\n",
      "   ‚Üí Columns: filename, actual, predicted, confidence, status, top3\n",
      "\n",
      "‚úÖ predictions_summary.csv\n",
      "   ‚Üí Per-class accuracy summary\n",
      "   ‚Üí Columns: class_name, correct_count, wrong_count, total_count, accuracy\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "‚ùå FAILED TO PROCESS (14 images)\n",
      "================================================================================\n",
      "  ‚Ä¢ barbara palvin158_800.jpg: No face detected\n",
      "  ‚Ä¢ Eliza Taylor202_775.jpg: No face detected\n",
      "  ‚Ä¢ Elizabeth Lail102_1055.jpg: No face detected\n",
      "  ‚Ä¢ Elizabeth Lail102_1056.jpg: No face detected\n",
      "  ‚Ä¢ Elizabeth Lail194_1117.jpg: No face detected\n",
      "  ‚Ä¢ Emilia Clarke78_1050.jpg: No face detected\n",
      "  ‚Ä¢ Emma Stone73_1817.jpg: No face detected\n",
      "  ‚Ä¢ jeff bezos112_2049.jpg: No face detected\n",
      "  ‚Ä¢ jeff bezos12_2052.jpg: No face detected\n",
      "  ‚Ä¢ jeff bezos160_2068.jpg: No face detected\n",
      "  ‚Ä¢ jeff bezos178_2073.jpg: No face detected\n",
      "  ‚Ä¢ Jeremy Renner175_2634.jpg: No face detected\n",
      "  ‚Ä¢ Johnny Depp23_1863.jpg: No face detected\n",
      "  ‚Ä¢ Johnny Depp42_1892.jpg: No face detected\n",
      "\n",
      "‚úÖ Failed images list saved to: failed_predictions.csv\n",
      "\n",
      "================================================================================\n",
      "‚úÖ PROCESSING COMPLETE!\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "id": "b34fec9d3eb4e0ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T07:43:27.914204Z",
     "start_time": "2025-12-20T07:43:27.899578Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
